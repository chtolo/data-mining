import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing import image
from sklearn.model_selection import train_test_split

# Charger le dataset Boston Housing
url='https://github.com/chtolo/data-mining/blob/main/boston_housing_clean.csv'
df = pd.read_csv(url)

# Prétraitement des données d'image (à adapter selon le format des images)
def load_and_preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = img_array / 255.0  # Normalisation des pixels
    return img_array

# Charger les images et prétraiter
image_paths = df['image_paths']  # Colonne contenant les chemins d'accès aux images
X_images = np.array([load_and_preprocess_image(path) for path in image_paths])

# Séparer les caractéristiques (features) et la variable cible
X_other_features = df.drop(['medv', 'image_paths'], axis=1)  # Caractéristiques autres que les images
y = df['medv']  # Prix médian des logements (variable cible)

# Diviser les données en ensembles d'entraînement et de test
X_images_train, X_images_test, X_other_train, X_other_test, y_train, y_test = train_test_split(
    X_images, X_other_features, y, test_size=0.2, random_state=42
)

# Créer le modèle CNN
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(256, activation='relu'),
    Dense(1)  # Couche de sortie pour la prédiction du prix médian
])

# Compiler le modèle
model.compile(optimizer='adam', loss='mse')  # MSE (Mean Squared Error) pour la régression

# Entraîner le modèle
model.fit([X_images_train, X_other_train], y_train, epochs=10, batch_size=32, validation_split=0.2)

# Évaluer le modèle sur l'ensemble de test
loss = model.evaluate([X_images_test, X_other_test], y_test)
print("Test Loss:", loss)

# Faire une prédiction sur un nouvel ensemble de données
# Assurez-vous de prétraiter les nouvelles images de la même manière que les données d'entraînement
# Utilisez model.predict() pour obtenir les prédictions sur cet ensemble de données
